{"cursor":"49536","size":14,"audio":[],"currentlang":"en","article":"In information theory, 'entropy' is a measure of the uncertainty in a\nrandom variable. In this context, the term usually refers to\nthe 'Shannon entropy', which quantifies the expected value of the\ninformation contained in a message. In this context, a 'message' means\na specific realization of the random variable. Entropy is typically\nmeasured in bits, nats, or bans. Shannon entropy is the average\nunpredictability in a random variable, which is equivalent to its\ninformation content. The concept was introduced by Claude E. Shannon in\nhis 1948 paper \"A Mathematical Theory of Communication\". ([http://www.alcatel-lucent.com/bstj/vol27-1948/articles/bstj27-3-\n379.pdf PDF]) Shannon entropy provides an absolute limit on the best\npossible lossless encoding or compression of any communication, assuming\nthat the communication may be represented as a sequence of\nindependent and identically distributed random variables. Shannon's source\ncoding theorem shows that, in the limit, the average length of the\nshortest possible representation to encode the messages in a given\nalphabet is their entropy divided by the logarithm of the number of\nsymbols in the target alphabet.\n\nA single toss of a fair coin has an entropy of one bit. A series of two fair\ncoin tosses has an entropy of two bits. The number of fair coin tosses is its\nentropy in bits. This random selection between two outcomes in a sequence over\ntime, whether the outcomes are equally probable or not, is often referred to as\na Bernoulli process. The entropy of such a process is given by the binary\nentropy function. The entropy rate for a fair coin toss is one bit per toss.\nHowever, if the coin is not fair, then the uncertainty, and hence the entropy\nrate, is lower. This is because, if asked to predict the next outcome, we could\nchoose the most frequent result and be right more often than wrong. The\ndifference between what we know, or predict, and the information that the unfair\ncoin toss reveals to us is less than one heads-or-tails \"message\", or bit, per\ntoss. As another example, the entropy rate of English text is between 1.0 and\n1.5 bits per letter, Schneier, B: Applied\nCryptography, Second edition, page 234. John Wiley and Sons. or as low as\n0.6 to 1.3 bits per letter, according to estimates by Shannon based on\nexperiments where humans were asked to predict the next letter in a sample of\nEnglish text. Shannon, Claude E.: Prediction\nand entropy of printed English, [[The Bell System Technical Journal]], 30:50â64,\nJanuary 1951.\n","linknr":623,"url":"Information_entropy","recorded":1371230385,"links":["/w/index.php?title=Entropy_(information_theory)&action=edit","/w/index.php?title=Entropy_(information_theory)&action=edit","//bits.wikimedia.org/favicon/wikipedia.ico","/w/opensearch_desc.php","//en.wikipedia.org/w/api.php?action=rsd","//creativecommons.org/licenses/by-sa/3.0/","/w/index.php?title=Special:RecentChanges&feed=atom","/wiki/Entropy_(information_theory)","//bits.wikimedia.org/en.wikipedia.org/load.php?debug=false&lang=en&modules=ext.gadget.DRN-wizard%2CReferenceTooltips%2Ccharinsert%2Cteahouse%7Cext.rtlcite%2Cwikihiero%7Cmediawiki.legacy.commonPrint%2Cshared%7Cmw.PopUpMediaTransform%7Cskins.vector&only=styles&skin=vector&*","//bits.wikimedia.org/en.wikipedia.org/load.php?debug=false&lang=en&modules=site&only=styles&skin=vector&*","//bits.wikimedia.org/en.wikipedia.org/load.php?debug=false&lang=en&modules=startup&only=scripts&skin=vector&*","//bits.wikimedia.org/geoiplookup","//meta.wikimedia.org","/w/index.php?title=Information_entropy&redirect=no","#mw-navigation","#p-search","/wiki/Information_theory","/wiki/Random_variable","#cite_note-1","/wiki/Expected_value","/wiki/Self-information","#cite_note-2","/wiki/Bit","/wiki/Nat_(information)","/wiki/Ban_(information)","#cite_note-3","/wiki/Information_content","/wiki/Claude_E._Shannon","/wiki/A_Mathematical_Theory_of_Communication","#cite_note-4","/wiki/Lossless","/wiki/Data_compression","#cite_note-5","/wiki/Independent_and_identically_distributed_random_variables","/wiki/Shannon%27s_source_coding_theorem","/wiki/Alphabet_(computer_science)","/wiki/Wikipedia:Citation_needed","/wiki/Fair_coin","/wiki/Bernoulli_process","/wiki/Binary_entropy_function","/wiki/Entropy_rate","/wiki/Bit","#cite_note-Schneier.2C_B_page_234-6","#cite_note-Shannon.2C_Claude_E._1951-7","#Introduction","#Definition","#Example","#Rationale","#Aspects","#Relationship_to_thermodynamic_entropy","#Entropy_as_information_content","#Data_compression","#World.27s_technological_capacity_to_store_and_communicate_entropic_information","#Limitations_of_entropy_as_information_content","#Limitations_of_entropy_as_a_measure_of_unpredictability","#Data_as_a_Markov_process","#b-ary_entropy","#Efficiency","#Characterization","#Continuity","#Symmetry","#Maximum","#Additivity","#Further_properties","#Extending_discrete_entropy_to_the_continuous_case:_differential_entropy","#Relative_Entropy","#Use_in_combinatorics","#Loomis-Whitney_inequality","#Approximation_to_binomial_coefficient","#See_also","#References","#Further_reading","#External_links","/w/index.php?title=Entropy_(information_theory)&action=edit&section=1","/wiki/Bit","/wiki/ASCII","#cite_note-Schneier.2C_B_page_234-6","#cite_note-Shannon.2C_Claude_E._1951-7","/wiki/Data_compression","/wiki/Shannon%27s_source_coding_theorem","/wiki/FLAC","/w/index.php?title=Entropy_(information_theory)&action=edit&section=2","/wiki/H-theorem","/wiki/Discrete_random_variable","/wiki/Probability_mass_function","//upload.wikimedia.org/math/3/8/a/38ad97542e92e1f9b6a99279e0057304.png","/wiki/Expected_value","/wiki/Self-information","#cite_note-8","#cite_note-9","//upload.wikimedia.org/math/9/4/7/947a86871452f7cb47ca53e01b362220.png","/wiki/Base_(exponentiation)","/wiki/Logarithm","/wiki/E_(mathematical_constant)","/wiki/Bit","/wiki/Nat_(information)","/wiki/Dit_(information)","#cite_note-10","/wiki/Limit_of_a_function","//upload.wikimedia.org/math/7/0/0/700dfd496533cb05a810021fdf9f0b45.png","/w/index.php?title=Entropy_(information_theory)&action=edit&section=3","/wiki/File:Binary_entropy_plot.svg","//upload.wikimedia.org/wikipedia/commons/thumb/2/22/Binary_entropy_plot.svg/200px-Binary_entropy_plot.svg.png","/wiki/File:Binary_entropy_plot.svg","//bits.wikimedia.org/static-1.22wmf5/skins/common/images/magnify-clip.png","/wiki/Expected_value","/wiki/Binary_entropy_function","/wiki/Bernoulli_process","/wiki/Bernoulli_process","/wiki/Bit","/wiki/Metric_entropy","/w/index.php?title=Entropy_(information_theory)&action=edit&section=4","//upload.wikimedia.org/math/8/7/e/87efdf0d38947240683250d3a24466e0.png","/wiki/Probability_mass_function","/wiki/Die","//upload.wikimedia.org/math/4/8/4/484ed5744427a8cbe7a672e3b11d09a9.png","/wiki/Die","/wiki/Die","//upload.wikimedia.org/math/e/5/f/e5fee68a2b25129f3a20d2f3c080c35e.png","//upload.wikimedia.org/math/b/d/8/bd8adbb856549d8c9e11e1c434e390aa.png","//upload.wikimedia.org/math/8/a/6/8a63ddc8363705ab6bc839df240388a0.png","//upload.wikimedia.org/math/c/7/5/c75218a5a78c21376ded00b64656ef06.png","/wiki/Self-information","//upload.wikimedia.org/math/e/d/4/ed49550c10cd09d380af6bb7a09d15cf.png","//upload.wikimedia.org/math/a/8/3/a83a3cd377b4f6d1d2127b36bff15e51.png","//upload.wikimedia.org/math/d/b/9/db98f9b2313e8bd96727165e04553680.png","#cite_note-11","//upload.wikimedia.org/math/6/7/a/67ae8a64f4bdcd4d26082346d6df5f52.png","/w/index.php?title=Entropy_(information_theory)&action=edit&section=5","/w/index.php?title=Entropy_(information_theory)&action=edit&section=6","/wiki/Entropy_in_thermodynamics_and_information_theory","/wiki/Thermodynamics","/wiki/Statistical_thermodynamics","/wiki/Entropy","/wiki/Thermodynamic_system","/wiki/Entropy_(statistical_thermodynamics)#Gibbs_Entropy_Formula","//upload.wikimedia.org/math/b/b/f/bbfbc6b205f58a1ba0315564799ef5d2.png","/wiki/Boltzmann_constant","/wiki/J._Willard_Gibbs","/wiki/Ludwig_Boltzmann","#cite_note-12","/wiki/Quantum_physics","/wiki/Von_Neumann_entropy","/wiki/John_von_Neumann","//upload.wikimedia.org/math/2/b/a/2bae64917eaf018fd03619f3c9d99982.png","/wiki/Density_matrix","/wiki/Trace_(linear_algebra)","/wiki/Second_law_of_thermodynamics","/wiki/Boltzmann%27s_constant","/wiki/Edwin_Thompson_Jaynes","/wiki/Statistical_mechanics","/wiki/Boltzmann_constant","/wiki/Maximum_entropy_thermodynamics","/wiki/Maxwell%27s_demon","/wiki/Rolf_Landauer","/wiki/Landauer%27s_principle","/w/index.php?title=Entropy_(information_theory)&action=edit&section=7","/wiki/Shannon%27s_source_coding_theorem","/wiki/Bit","#cite_note-13","/wiki/PPM_compression_algorithm","/wiki/Shannon-Hartley_theorem","/wiki/Markov_chain","/w/index.php?title=Entropy_(information_theory)&action=edit&section=8","/wiki/Data_compression","/wiki/Typical_set","/wiki/Huffman_coding","/wiki/LZW","/wiki/Arithmetic_coding","#cite_note-14","#cite_note-15","/wiki/Kolmogorov_complexity","/wiki/Checksum","/w/index.php?title=Entropy_(information_theory)&action=edit&section=9","/wiki/Science_(journal)","#cite_note-HilbertLopez2011-16","/wiki/Exabytes","/wiki/Exabytes","/wiki/Broadcast","/wiki/Exabytes","/wiki/Zettabytes","/wiki/Telecommunication","/wiki/Petabytes","/wiki/Exabytes","#cite_note-HilbertLopez2011-16","/w/index.php?title=Entropy_(information_theory)&action=edit&section=10","/wiki/Self-information","/wiki/Entropy_rate","/wiki/Stochastic_process","/wiki/Stationary_process","/wiki/Quantities_of_information","/wiki/Entropy_rate","/wiki/Statistical_independence","/wiki/ISBN","/wiki/Kolmogorov_complexity","/wiki/Computer_program","/wiki/Universal_computer","/w/index.php?title=Entropy_(information_theory)&action=edit&section=11","/wiki/Cryptanalysis","//upload.wikimedia.org/math/2/d/1/2d1fdc985a090358026bafc8c9c71027.png","//upload.wikimedia.org/math/9/1/9/9194cb736f4a7d44a6f704f6f0c4baed.png","/wiki/Wikipedia:Please_clarify","//upload.wikimedia.org/math/0/a/6/0a6ec2f02951c6a821e14d177704044a.png","//upload.wikimedia.org/math/c/5/4/c545b37ff46c957bc921d947b8ff872e.png","/wiki/One-time_pad","/w/index.php?title=Entropy_(information_theory)&action=edit&section=12","/wiki/Markov_model","//upload.wikimedia.org/math/c/a/2/ca29f373129e5aa2a5d1ed24e51920dc.png","/wiki/Markov_source","/wiki/Entropy_rate","//upload.wikimedia.org/math/2/3/e/23e272a12e0592a866901203df55457c.png","/wiki/Wikipedia:Citation_needed","//upload.wikimedia.org/math/f/f/8/ff80e0c579eff2d8e4c51db5775b992d.png","//upload.wikimedia.org/math/3/8/8/388579cc2192bdd207ee3b048bcee6b3.png","/w/index.php?title=Entropy_(information_theory)&action=edit&section=13","//upload.wikimedia.org/math/3/7/9/3791545a70a6e462451c97ad925d43a4.png","/w/index.php?title=Source_alphabet&action=edit&redlink=1","/wiki/Discrete_probability_distribution","//upload.wikimedia.org/math/2/0/2/202ea0fca52e0f9154d56c29d7778fa6.png","/wiki/Necessary_and_sufficient","/wiki/Uniform_distribution_(discrete)","/w/index.php?title=Entropy_(information_theory)&action=edit&section=14","//upload.wikimedia.org/math/a/1/6/a160d334425f7d8d0867caa63b9acf0c.png","//upload.wikimedia.org/math/f/f/d/ffd8ef3eae1d07b52a14e1a9ed04a7c7.png","/w/index.php?title=Entropy_(information_theory)&action=edit&section=15","/wiki/Characterization_(mathematics)","//upload.wikimedia.org/math/d/4/b/d4ba18355fab2cd42a15f1c31469ccf5.png","//upload.wikimedia.org/math/b/5/d/b5d6ad4a679d927a41c1d972bd912383.png","/w/index.php?title=Entropy_(information_theory)&action=edit&section=16","/wiki/Continuous_function","/w/index.php?title=Entropy_(information_theory)&action=edit&section=17","//upload.wikimedia.org/math/3/a/f/3afd0f61009766137def9924a2e5556b.png","/w/index.php?title=Entropy_(information_theory)&action=edit&section=18","//upload.wikimedia.org/math/c/a/b/cabda3ce6963f9bfbee00a22674a400b.png","//upload.wikimedia.org/math/0/7/a/07aeb69f268e95be1350f895443d0343.png","/w/index.php?title=Entropy_(information_theory)&action=edit&section=19","/wiki/Positive_integers","//upload.wikimedia.org/math/9/3/2/932bdd0c9854b571a7461189283eaabc.png","/wiki/Redundancy_(information_theory)","/w/index.php?title=Entropy_(information_theory)&action=edit&section=20","//upload.wikimedia.org/math/9/1/6/91634d31e2670e8e826aeed172583eb0.png","/wiki/Jensen_inequality","//upload.wikimedia.org/math/d/9/5/d950adaead837c0ad9b5997282f9da9e.png","//upload.wikimedia.org/math/a/d/4/ad4aec19545a1e3c668f9558d38f4dce.png","//upload.wikimedia.org/math/1/8/5/1859f792e2f41bc40a067321284b0650.png","//upload.wikimedia.org/math/6/d/0/6d011f73a19ebca1d045345f48766de7.png","//upload.wikimedia.org/math/3/a/4/3a4d0c6ba32f90befe93ee8362587811.png","/w/index.php?title=Entropy_(information_theory)&action=edit&section=21","/wiki/Differential_entropy","/wiki/Probability_density_function","//upload.wikimedia.org/math/e/c/2/ec2516e7e6851ed5b818693359dc3940.png","/wiki/Differential_entropy","/wiki/H-theorem","/wiki/Boltzmann","/wiki/Limiting_density_of_discrete_points","/wiki/Bin_size","//upload.wikimedia.org/math/d/a/f/daf8aedf3eef9d77e23f39bc67feb716.png","//upload.wikimedia.org/math/4/4/0/440fde8068dfc0b0e9dd3766278a9055.png","//upload.wikimedia.org/math/b/6/f/b6fe1521f16290a9b7025c307a356ac7.png","//upload.wikimedia.org/math/8/f/4/8f472dadccf4d71f02d3651ae95e9ed8.png","//upload.wikimedia.org/math/c/a/7/ca768b8e96cd4a05c58aafc078edc7e4.png","//upload.wikimedia.org/math/5/3/6/536793456be62eae1397a8885ce672d2.png","/w/index.php?title=Entropy_(information_theory)&action=edit&section=22","/wiki/Kullback-Leibler_divergence","/wiki/Measure","/wiki/Absolutely_continuous","//upload.wikimedia.org/math/f/a/d/fadb67b95c5be349a35f4a3d33bdebfe.png","/wiki/Counting_measure","/wiki/Lebesgue_measure","/w/index.php?title=Entropy_(information_theory)&action=edit&section=23","/wiki/Combinatorics","/w/index.php?title=Entropy_(information_theory)&action=edit&section=24","/wiki/Loomis-Whitney_inequality","//upload.wikimedia.org/math/5/a/7/5a77e51d9cc1147ae69b0ff7daee8568.png","/wiki/Orthogonal_projection","//upload.wikimedia.org/math/c/7/c/c7c07787befe6cb52f5cff6f66509fa2.png","/wiki/Shearer%27s_inequality","//upload.wikimedia.org/math/3/1/a/31a85f9c121805adfc75f3e458e049c9.png","//upload.wikimedia.org/math/0/f/d/0fd8197d4910819dacbe3e85ad5e07e4.png","//upload.wikimedia.org/math/0/f/d/0fd8197d4910819dacbe3e85ad5e07e4.png","//upload.wikimedia.org/math/c/8/a/c8a2949b3b77933bccc24b4be6e2d3d1.png","/w/index.php?title=Entropy_(information_theory)&action=edit&section=25","//upload.wikimedia.org/math/6/f/f/6ff115fba156eea8ba3670a18935e9f3.png","//upload.wikimedia.org/math/b/8/e/b8ec80d3be8d33da41fcf4aa13d0a70e.png","#cite_note-17","//upload.wikimedia.org/math/9/4/5/94512ae8768feb7b6a814f5da2a0bfd3.png","//upload.wikimedia.org/math/c/d/0/cd0d32326fbc6d2dd8362b19d40f5bad.png","//upload.wikimedia.org/math/f/3/9/f39b136ba4c61a64f87ce4e652682ecd.png","//upload.wikimedia.org/math/8/b/b/8bb24584c4325d5f36d82eaf52b7e30e.png","#cite_note-18","/w/index.php?title=Entropy_(information_theory)&action=edit&section=26","/wiki/File:Fisher_iris_versicolor_sepalwidth.svg","//upload.wikimedia.org/wikipedia/commons/thumb/4/40/Fisher_iris_versicolor_sepalwidth.svg/32px-Fisher_iris_versicolor_sepalwidth.svg.png","/wiki/Portal:Statistics","/wiki/File:Crypto_key.svg","//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Crypto_key.svg/32px-Crypto_key.svg.png","/wiki/Portal:Cryptography","/wiki/Conditional_entropy","/wiki/Cross_entropy","/wiki/Entropy_(arrow_of_time)","/wiki/Entropy_encoding","/wiki/Entropy_estimation","/wiki/Entropy_power_inequality","/wiki/Entropy_rate","/wiki/Fisher_information","/wiki/Hamming_distance","/wiki/History_of_entropy","/wiki/History_of_information_theory","/wiki/Joint_entropy","/wiki/Kolmogorov-Sinai_entropy","/wiki/Dynamical_system","/wiki/Levenshtein_distance","/wiki/Mutual_information","/wiki/Negentropy","/wiki/Perplexity","/wiki/Qualitative_variation","/wiki/Statistical_dispersion","/wiki/Nominal_distributions","/wiki/Quantum_relative_entropy","/wiki/R%C3%A9nyi_entropy","/wiki/Shannon_index","/wiki/Theil_index","/wiki/Weighted_entropy","/w/index.php?title=Entropy_(information_theory)&action=edit&section=27","//upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/50px-Question_book-new.svg.png","//en.wikipedia.org/w/index.php?title=Entropy_(information_theory)&action=edit","/wiki/Help:Introduction_to_referencing/1","/wiki/Template:Citation_needed","/wiki/Wikipedia:Verifiability#Burden_of_evidence","#cite_ref-1","http://books.google.com/books?id=rwg5ndTuTC4C&pg=PA2","/wiki/International_Standard_Book_Number","/wiki/Special:BookSources/978-981-02-0985-8","#cite_ref-2","#cite_ref-3","http://books.google.com/books?id=DWo7lVRVnhcC&pg=PA293","/wiki/International_Standard_Book_Number","/wiki/Special:BookSources/978-0-486-43918-1","#cite_ref-4","/wiki/Claude_Shannon","/wiki/A_Mathematical_Theory_of_Communication","http://www.alcatel-lucent.com/bstj/vol27-1948/articles/bstj27-3-379.pdf","#cite_ref-5","http://books.google.com/books?id=K3meGQ9ntjgC&pg=PA14","/wiki/International_Standard_Book_Number","/wiki/Special:BookSources/978-3-540-73704-9","#cite_ref-Schneier.2C_B_page_234_6-0","#cite_ref-Schneier.2C_B_page_234_6-1","#cite_ref-Shannon.2C_Claude_E._1951_7-0","#cite_ref-Shannon.2C_Claude_E._1951_7-1","/wiki/The_Bell_System_Technical_Journal","#cite_ref-8","http://books.google.com/books?id=Lyte2yl1SPAC&pg=PA11","/wiki/International_Standard_Book_Number","/wiki/Special:BookSources/978-3-642-20346-6","#cite_ref-9","http://books.google.com/books?id=VpRESN24Zj0C&pg=PA19","/wiki/International_Standard_Book_Number","/wiki/Special:BookSources/978-0-8218-4256-0","#cite_ref-10","http://alum.mit.edu/www/toms/paper/primer/primer.pdf","#cite_ref-11","http://bayes.wustl.edu/etj/articles/theory.1.pdf","/wiki/Bibcode","http://adsabs.harvard.edu/abs/1957PhRv..106..620J","/wiki/Digital_object_identifier","http://dx.doi.org/10.1103%2FPhysRev.106.620","#cite_ref-12","/wiki/Special:BookSources/0486684555","#cite_ref-13","http://marknelson.us/2006/08/24/the-hutter-prize/","#cite_ref-14","http://arxiv.org/abs/cond-mat/0203436","#cite_ref-15","http://arxiv.org/abs/cond-mat/0403192","#cite_ref-HilbertLopez2011_16-0","#cite_ref-HilbertLopez2011_16-1","http://www.sciencemag.org/content/332/6025/60","/wiki/Science_(journal)","#cite_ref-17","#cite_ref-18","http://planetmath.org/?op=getobj&from=objects&id=968","/wiki/PlanetMath","/wiki/Wikipedia:CC-BY-SA","/w/index.php?title=Entropy_(information_theory)&action=edit&section=28","http://books.google.com/books?id=_77lvx7y8joC","/wiki/International_Standard_Book_Number","/wiki/Special:BookSources/978-0-521-17738-2","/w/index.php?title=Entropy_(information_theory)&action=edit&section=29","http://www.encyclopediaofmath.org/index.php?title=p/e035740","/wiki/Encyclopedia_of_Mathematics","/wiki/Springer_Science%2BBusiness_Media","/wiki/International_Standard_Book_Number","/wiki/Special:BookSources/978-1-55608-010-4","http://pespmc1.vub.ac.be/ENTRINFO.html","/wiki/Principia_Cybernetica_Web","http://www.mdpi.com/journal/entropy","http://alum.mit.edu/www/toms/information.is.not.uncertainty.html","http://alum.mit.edu/www/toms/bionet.info-theory.faq.html#Information.Equal.Entropy","http://www.rheingold.com/texts/tft/6.html","http://math.ucsd.edu/~crypto/java/ENTROPY/","http://www.autonlab.org/tutorials/infogain.html","http://en.wikibooks.org/wiki/An_Intuitive_Guide_to_the_Concept_of_Entropy_Arising_in_Various_Sectors_of_Science","http://www.shannonentropy.netmark.pl","https://researchspace.auckland.ac.nz/handle/2292/3427","/wiki/Template:Compression_methods","/wiki/Template_talk:Compression_methods","//en.wikipedia.org/w/index.php?title=Template:Compression_methods&action=edit","/wiki/Data_compression","/wiki/Information_theory","/wiki/Kolmogorov_complexity","/wiki/Lossy_compression","/wiki/Quantization_(signal_processing)","/wiki/Rate%E2%80%93distortion_theory","/wiki/Redundancy_(information_theory)","/wiki/Timeline_of_information_theory","/wiki/Lossless_compression","/wiki/Entropy_encoding","/wiki/Arithmetic_coding","/wiki/Golomb_coding","/wiki/Huffman_coding","/wiki/Adaptive_Huffman_coding","/wiki/Canonical_Huffman_code","/wiki/Modified_Huffman_coding","/wiki/Range_encoding","/wiki/Shannon%E2%80%93Fano_coding","/wiki/Shannon%E2%80%93Fano%E2%80%93Elias_coding","/wiki/Tunstall_coding","/wiki/Universal_code_(data_compression)","/wiki/Exponential-Golomb_coding","/wiki/Fibonacci_coding","/wiki/Elias_gamma_coding","/wiki/Levenstein_coding","/wiki/Dictionary_coder","/wiki/Byte_pair_encoding","/wiki/DEFLATE","/wiki/LZ77_and_LZ78","/wiki/LZJB","/wiki/Lempel%E2%80%93Ziv%E2%80%93Markov_chain_algorithm","/wiki/Lempel%E2%80%93Ziv%E2%80%93Oberhumer","/wiki/LZRW","/wiki/Lempel%E2%80%93Ziv%E2%80%93Stac","/wiki/Lempel%E2%80%93Ziv%E2%80%93Storer%E2%80%93Szymanski","/w/index.php?title=Lempel%E2%80%93Ziv%E2%80%93Tamayo&action=edit&redlink=1","/wiki/Lempel%E2%80%93Ziv%E2%80%93Welch","/wiki/LZWL","/wiki/LZX_(algorithm)","/w/index.php?title=Reduced_Offset_Lempel_Ziv&action=edit&redlink=1","/wiki/Statistical_Lempel_Ziv","/wiki/Run-length_encoding","/wiki/Burrows%E2%80%93Wheeler_transform","/wiki/Context_tree_weighting","/wiki/Delta_encoding","/wiki/Dynamic_Markov_compression","/wiki/Prediction_by_partial_matching","/wiki/Audio_compression_(data)","/wiki/Acoustics","/wiki/Companding","/wiki/Convolution","/wiki/Dynamic_range","/wiki/Latency_(audio)","/wiki/Nyquist%E2%80%93Shannon_sampling_theorem","/wiki/Sampling_(signal_processing)","/wiki/Sound_quality","/wiki/Audio_codec","/wiki/A-law_algorithm","/wiki/%CE%9C-law_algorithm","/wiki/Algebraic_code-excited_linear_prediction","/wiki/Adaptive_differential_pulse-code_modulation","/wiki/Code-excited_linear_prediction","/wiki/Differential_pulse-code_modulation","/wiki/Fourier_transform","/wiki/Linear_predictive_coding","/wiki/Log_area_ratio","/wiki/Line_spectral_pairs","/wiki/Modified_discrete_cosine_transform","/wiki/Psychoacoustics","/wiki/Warped_linear_predictive_coding","/wiki/Bit_rate","/wiki/Average_bitrate","/wiki/Constant_bitrate","/wiki/Variable_bitrate","/wiki/Speech_coding","/wiki/Sub-band_coding","/wiki/Image_compression","/wiki/Chroma_subsampling","/wiki/Color_space","/wiki/Compression_artifact","/wiki/Image_resolution","/wiki/Macroblock","/wiki/Pixel","/wiki/Chain_code","/wiki/Discrete_cosine_transform","/wiki/Embedded_Zerotrees_of_Wavelet_transforms","/wiki/Fractal_compression","/wiki/Karhunen%E2%80%93Lo%C3%A8ve_theorem","/wiki/Pyramid_(image_processing)","/wiki/Run-length_encoding","/wiki/Set_partitioning_in_hierarchical_trees","/wiki/Wavelet_compression","/wiki/Peak_signal-to-noise_ratio","/wiki/Quantization_(image_processing)","/wiki/Standard_test_image","/wiki/Video_compression","/wiki/Display_resolution","/wiki/Film_frame","/wiki/Frame_rate","/wiki/Video_compression_picture_types","/wiki/Interlaced_video","/wiki/Video#Characteristics_of_video_streams","/wiki/Video_quality","/wiki/Video_codec","/wiki/Discrete_cosine_transform","/wiki/Deblocking_filter","/wiki/Motion_compensation","/wiki/Bit_rate","/wiki/Average_bitrate","/wiki/Constant_bitrate","/wiki/Variable_bitrate","/wiki/List_of_codecs#Lossless_compression","/wiki/Uncompressed_video","/wiki/Video_codec","/wiki/Template:Compression_formats","/wiki/Template:Compression_software","http://en.wikipedia.org/w/index.php?title=Entropy_(information_theory)&oldid=559188581","/wiki/Help:Categories","/wiki/Category:Entropy_and_information","/wiki/Category:Information_theory","/wiki/Category:Statistical_theory","/wiki/Category:Randomness","/wiki/Category:All_articles_with_unsourced_statements","/wiki/Category:Articles_with_unsourced_statements_from_April_2012","/wiki/Category:Wikipedia_articles_needing_clarification_from_April_2013","/wiki/Category:Articles_with_unsourced_statements_from_April_2013","/wiki/Category:Articles_needing_additional_references_from_April_2012","/wiki/Category:All_articles_needing_additional_references","/wiki/Category:Wikipedia_articles_incorporating_text_from_PlanetMath","/wiki/Category:Use_dmy_dates_from_September_2010","/w/index.php?title=Special:UserLogin&returnto=Entropy+%28information+theory%29&type=signup","/w/index.php?title=Special:UserLogin&returnto=Entropy+%28information+theory%29","/wiki/Entropy_(information_theory)","/wiki/Talk:Entropy_(information_theory)","#","/wiki/Entropy_(information_theory)","/w/index.php?title=Entropy_(information_theory)&action=edit","/w/index.php?title=Entropy_(information_theory)&action=history","#","/w/index.php","//bits.wikimedia.org/static-1.22wmf5/skins/vector/images/search-ltr.png?303-4","/wiki/Main_Page","/wiki/Main_Page","/wiki/Portal:Contents","/wiki/Portal:Featured_content","/wiki/Portal:Current_events","/wiki/Special:Random","//donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&utm_medium=sidebar&utm_campaign=C13_en.wikipedia.org&uselang=en","/wiki/Help:Contents","/wiki/Wikipedia:About","/wiki/Wikipedia:Community_portal","/wiki/Special:RecentChanges","//en.wikipedia.org/wiki/Wikipedia:Contact_us","/wiki/Special:WhatLinksHere/Entropy_(information_theory)","/wiki/Special:RecentChangesLinked/Entropy_(information_theory)","/wiki/Wikipedia:File_Upload_Wizard","/wiki/Special:SpecialPages","/w/index.php?title=Entropy_(information_theory)&oldid=559188581","/w/index.php?title=Entropy_(information_theory)&action=info","/w/index.php?title=Special:Cite&page=Entropy_%28information_theory%29&id=559188581","/w/index.php?title=Special:Book&bookcmd=book_creator&referer=Entropy+%28information+theory%29","/w/index.php?title=Special:Book&bookcmd=render_article&arttitle=Entropy+%28information+theory%29&oldid=559188581&writer=rl","/w/index.php?title=Entropy_(information_theory)&printable=yes","//ar.wikipedia.org/wiki/%D8%A7%D8%B9%D8%AA%D9%84%D8%A7%D8%AC_(%D9%86%D8%B8%D8%B1%D9%8A%D8%A9_%D8%A7%D9%84%D9%85%D8%B9%D9%84%D9%88%D9%85%D8%A7%D8%AA)","//bg.wikipedia.org/wiki/%D0%95%D0%BD%D1%82%D1%80%D0%BE%D0%BF%D0%B8%D1%8F_%D0%BD%D0%B0_%D0%A8%D0%B0%D0%BD%D1%8A%D0%BD","//bar.wikipedia.org/wiki/Entropie_(Informationstheorie)","//bs.wikipedia.org/wiki/Entropija_(teorija_informacija)","//ca.wikipedia.org/wiki/Entropia_de_Shannon","//cy.wikipedia.org/wiki/Entropi_gwybodaeth","//de.wikipedia.org/wiki/Entropie_(Informationstheorie)","//el.wikipedia.org/wiki/%CE%95%CE%BD%CF%84%CF%81%CE%BF%CF%80%CE%AF%CE%B1_%CF%80%CE%BB%CE%B7%CF%81%CE%BF%CF%86%CE%BF%CF%81%CE%B9%CF%8E%CE%BD","//es.wikipedia.org/wiki/Entrop%C3%ADa_(informaci%C3%B3n)","//fa.wikipedia.org/wiki/%D8%A2%D9%86%D8%AA%D8%B1%D9%88%D9%BE%DB%8C_%D8%A7%D8%B7%D9%84%D8%A7%D8%B9%D8%A7%D8%AA","//fr.wikipedia.org/wiki/Entropie_de_Shannon","//ko.wikipedia.org/wiki/%EC%A0%95%EB%B3%B4_%EC%97%94%ED%8A%B8%EB%A1%9C%ED%94%BC","//it.wikipedia.org/wiki/Entropia_(teoria_dell%27informazione)","//he.wikipedia.org/wiki/%D7%90%D7%A0%D7%98%D7%A8%D7%95%D7%A4%D7%99%D7%94_(%D7%A1%D7%98%D7%98%D7%99%D7%A1%D7%98%D7%99%D7%A7%D7%94)","//lt.wikipedia.org/wiki/Entropija_(informacijos_teorija)","//hu.wikipedia.org/wiki/Shannon-entr%C3%B3piaf%C3%BCggv%C3%A9ny","//nl.wikipedia.org/wiki/Entropie_(informatietheorie)","//ja.wikipedia.org/wiki/%E6%83%85%E5%A0%B1%E9%87%8F","//mhr.wikipedia.org/wiki/%D0%A8%D0%B5%D0%BD%D0%BD%D0%BE%D0%BD%D1%8B%D0%BD_%D1%84%D0%BE%D1%80%D0%BC%D1%83%D0%BB%D0%B6%D0%BE","//pl.wikipedia.org/wiki/Entropia_(teoria_informacji)","//pt.wikipedia.org/wiki/Entropia_da_informa%C3%A7%C3%A3o","//ro.wikipedia.org/wiki/Entropie_informa%C8%9Bional%C4%83","//ru.wikipedia.org/wiki/%D0%98%D0%BD%D1%84%D0%BE%D1%80%D0%BC%D0%B0%D1%86%D0%B8%D0%BE%D0%BD%D0%BD%D0%B0%D1%8F_%D1%8D%D0%BD%D1%82%D1%80%D0%BE%D0%BF%D0%B8%D1%8F","//simple.wikipedia.org/wiki/Information_entropy","//sk.wikipedia.org/wiki/Entropia_(te%C3%B3ria_inform%C3%A1ci%C3%AD)","//sl.wikipedia.org/wiki/Entropija_(informatika)","//ckb.wikipedia.org/wiki/%D8%A6%D8%A7%D9%86%D8%AA%D8%B1%DB%86%D9%BE%DB%8C%DB%8C_%D8%B2%D8%A7%D9%86%DB%8C%D8%A7%D8%B1%DB%8C","//sr.wikipedia.org/wiki/%D0%95%D0%BD%D1%82%D1%80%D0%BE%D0%BF%D0%B8%D1%98%D0%B0_(%D1%82%D0%B5%D0%BE%D1%80%D0%B8%D1%98%D0%B0_%D0%B8%D0%BD%D1%84%D0%BE%D1%80%D0%BC%D0%B0%D1%86%D0%B8%D1%98%D0%B0)","//su.wikipedia.org/wiki/%C3%89ntropi_informasi","//sv.wikipedia.org/wiki/Entropi_(informationsteori)","//te.wikipedia.org/wiki/%E0%B0%B8%E0%B0%AE%E0%B0%BE%E0%B0%9A%E0%B0%BE%E0%B0%B0_%E0%B0%B8%E0%B0%82%E0%B0%95%E0%B0%B0%E0%B0%A4_(%E0%B0%87%E0%B0%A8%E0%B1%8D%E0%B0%AB%E0%B0%B0%E0%B1%8D%E0%B0%AE%E0%B1%87%E0%B0%B7%E0%B0%A8%E0%B1%8D_%E0%B0%8E%E0%B0%82%E0%B0%9F%E0%B1%8D%E0%B0%B0%E0%B1%8A%E0%B0%AA%E0%B1%80)","//th.wikipedia.org/wiki/%E0%B9%80%E0%B8%AD%E0%B8%99%E0%B9%82%E0%B8%97%E0%B8%A3%E0%B8%9B%E0%B8%B5%E0%B8%82%E0%B8%AD%E0%B8%87%E0%B8%82%E0%B9%89%E0%B8%AD%E0%B8%A1%E0%B8%B9%E0%B8%A5","//uk.wikipedia.org/wiki/%D0%86%D0%BD%D1%84%D0%BE%D1%80%D0%BC%D0%B0%D1%86%D1%96%D0%B9%D0%BD%D0%B0_%D0%B5%D0%BD%D1%82%D1%80%D0%BE%D0%BF%D1%96%D1%8F","//ur.wikipedia.org/wiki/%D8%AF%D8%B1%D9%85%D8%A7%D8%A6%D9%84%D8%AA_(%D8%A7%D8%B7%D9%84%D8%A7%D8%B9%D8%A7%D8%AA%DB%8C_%D9%86%D8%B8%D8%B1%DB%8C%DB%81)","//vi.wikipedia.org/wiki/Entropy_th%C3%B4ng_tin","//zh.wikipedia.org/wiki/%E7%86%B5_(%E4%BF%A1%E6%81%AF%E8%AE%BA)","//www.wikidata.org/wiki/Q204570#sitelinks","//en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License","//creativecommons.org/licenses/by-sa/3.0/","//wikimediafoundation.org/wiki/Terms_of_Use","//wikimediafoundation.org/wiki/Privacy_policy","//www.wikimediafoundation.org/","//wikimediafoundation.org/wiki/Privacy_policy","/wiki/Wikipedia:About","/wiki/Wikipedia:General_disclaimer","//en.wikipedia.org/wiki/Wikipedia:Contact_us","http://en.m.wikipedia.org/wiki/Entropy_(information_theory)","//wikimediafoundation.org/","//bits.wikimedia.org/images/wikimedia-button.png","//www.mediawiki.org/","//bits.wikimedia.org/static-1.22wmf5/skins/common/images/poweredby_mediawiki_88x31.png","/w/index.php?title=MediaWiki:Gadget-ReferenceTooltips.js&action=raw&ctype=text/javascript&508635914","//bits.wikimedia.org/en.wikipedia.org/load.php?debug=false&lang=en&modules=site&only=scripts&skin=vector&*"],"instances":["mathematical_constant","exponentiation","arrow_of_time","information","discrete","information","mathematics","computer_science","linear_algebra","journal","information_theory","information"],"pdf":["http://alum.mit.edu/www/toms/paper/primer/primer.pdf"],"categories":["Entropy and information|","Information theory","Statistical theory","Randomness"],"headings":["Introduction","Definition","Example","Rationale","Aspects","Efficiency","Characterization","Further properties","Extending discrete entropy to the continuous case: differential entropy","Relative Entropy","Use in combinatorics","See also","References","Further reading","External links"],"image":["//upload.wikimedia.org/math/3/8/a/38ad97542e92e1f9b6a99279e0057304.png","//upload.wikimedia.org/math/9/4/7/947a86871452f7cb47ca53e01b362220.png","//upload.wikimedia.org/math/7/0/0/700dfd496533cb05a810021fdf9f0b45.png","//upload.wikimedia.org/wikipedia/commons/thumb/2/22/Binary_entropy_plot.svg/200px-Binary_entropy_plot.svg.png","//bits.wikimedia.org/static-1.22wmf5/skins/common/images/magnify-clip.png","//upload.wikimedia.org/math/8/7/e/87efdf0d38947240683250d3a24466e0.png","//upload.wikimedia.org/math/4/8/4/484ed5744427a8cbe7a672e3b11d09a9.png","//upload.wikimedia.org/math/e/5/f/e5fee68a2b25129f3a20d2f3c080c35e.png","//upload.wikimedia.org/math/b/d/8/bd8adbb856549d8c9e11e1c434e390aa.png","//upload.wikimedia.org/math/8/a/6/8a63ddc8363705ab6bc839df240388a0.png","//upload.wikimedia.org/math/c/7/5/c75218a5a78c21376ded00b64656ef06.png","//upload.wikimedia.org/math/e/d/4/ed49550c10cd09d380af6bb7a09d15cf.png","//upload.wikimedia.org/math/a/8/3/a83a3cd377b4f6d1d2127b36bff15e51.png","//upload.wikimedia.org/math/d/b/9/db98f9b2313e8bd96727165e04553680.png","//upload.wikimedia.org/math/6/7/a/67ae8a64f4bdcd4d26082346d6df5f52.png","//upload.wikimedia.org/math/b/b/f/bbfbc6b205f58a1ba0315564799ef5d2.png","//upload.wikimedia.org/math/2/b/a/2bae64917eaf018fd03619f3c9d99982.png","//upload.wikimedia.org/math/2/d/1/2d1fdc985a090358026bafc8c9c71027.png","//upload.wikimedia.org/math/9/1/9/9194cb736f4a7d44a6f704f6f0c4baed.png","//upload.wikimedia.org/math/0/a/6/0a6ec2f02951c6a821e14d177704044a.png","//upload.wikimedia.org/math/c/5/4/c545b37ff46c957bc921d947b8ff872e.png","//upload.wikimedia.org/math/c/a/2/ca29f373129e5aa2a5d1ed24e51920dc.png","//upload.wikimedia.org/math/2/3/e/23e272a12e0592a866901203df55457c.png","//upload.wikimedia.org/math/f/f/8/ff80e0c579eff2d8e4c51db5775b992d.png","//upload.wikimedia.org/math/3/8/8/388579cc2192bdd207ee3b048bcee6b3.png","//upload.wikimedia.org/math/3/7/9/3791545a70a6e462451c97ad925d43a4.png","//upload.wikimedia.org/math/2/0/2/202ea0fca52e0f9154d56c29d7778fa6.png","//upload.wikimedia.org/math/a/1/6/a160d334425f7d8d0867caa63b9acf0c.png","//upload.wikimedia.org/math/f/f/d/ffd8ef3eae1d07b52a14e1a9ed04a7c7.png","//upload.wikimedia.org/math/d/4/b/d4ba18355fab2cd42a15f1c31469ccf5.png","//upload.wikimedia.org/math/b/5/d/b5d6ad4a679d927a41c1d972bd912383.png","//upload.wikimedia.org/math/3/a/f/3afd0f61009766137def9924a2e5556b.png","//upload.wikimedia.org/math/c/a/b/cabda3ce6963f9bfbee00a22674a400b.png","//upload.wikimedia.org/math/0/7/a/07aeb69f268e95be1350f895443d0343.png","//upload.wikimedia.org/math/9/3/2/932bdd0c9854b571a7461189283eaabc.png","//upload.wikimedia.org/math/9/1/6/91634d31e2670e8e826aeed172583eb0.png","//upload.wikimedia.org/math/d/9/5/d950adaead837c0ad9b5997282f9da9e.png","//upload.wikimedia.org/math/a/d/4/ad4aec19545a1e3c668f9558d38f4dce.png","//upload.wikimedia.org/math/1/8/5/1859f792e2f41bc40a067321284b0650.png","//upload.wikimedia.org/math/6/d/0/6d011f73a19ebca1d045345f48766de7.png","//upload.wikimedia.org/math/3/a/4/3a4d0c6ba32f90befe93ee8362587811.png","//upload.wikimedia.org/math/e/c/2/ec2516e7e6851ed5b818693359dc3940.png","//upload.wikimedia.org/math/d/a/f/daf8aedf3eef9d77e23f39bc67feb716.png","//upload.wikimedia.org/math/4/4/0/440fde8068dfc0b0e9dd3766278a9055.png","//upload.wikimedia.org/math/b/6/f/b6fe1521f16290a9b7025c307a356ac7.png","//upload.wikimedia.org/math/8/f/4/8f472dadccf4d71f02d3651ae95e9ed8.png","//upload.wikimedia.org/math/c/a/7/ca768b8e96cd4a05c58aafc078edc7e4.png","//upload.wikimedia.org/math/5/3/6/536793456be62eae1397a8885ce672d2.png","//upload.wikimedia.org/math/f/a/d/fadb67b95c5be349a35f4a3d33bdebfe.png","//upload.wikimedia.org/math/5/a/7/5a77e51d9cc1147ae69b0ff7daee8568.png","//upload.wikimedia.org/math/c/7/c/c7c07787befe6cb52f5cff6f66509fa2.png","//upload.wikimedia.org/math/3/1/a/31a85f9c121805adfc75f3e458e049c9.png","//upload.wikimedia.org/math/0/f/d/0fd8197d4910819dacbe3e85ad5e07e4.png","//upload.wikimedia.org/math/0/f/d/0fd8197d4910819dacbe3e85ad5e07e4.png","//upload.wikimedia.org/math/c/8/a/c8a2949b3b77933bccc24b4be6e2d3d1.png","//upload.wikimedia.org/math/6/f/f/6ff115fba156eea8ba3670a18935e9f3.png","//upload.wikimedia.org/math/b/8/e/b8ec80d3be8d33da41fcf4aa13d0a70e.png","//upload.wikimedia.org/math/9/4/5/94512ae8768feb7b6a814f5da2a0bfd3.png","//upload.wikimedia.org/math/c/d/0/cd0d32326fbc6d2dd8362b19d40f5bad.png","//upload.wikimedia.org/math/f/3/9/f39b136ba4c61a64f87ce4e652682ecd.png","//upload.wikimedia.org/math/8/b/b/8bb24584c4325d5f36d82eaf52b7e30e.png","//upload.wikimedia.org/wikipedia/commons/thumb/4/40/Fisher_iris_versicolor_sepalwidth.svg/32px-Fisher_iris_versicolor_sepalwidth.svg.png","//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Crypto_key.svg/32px-Crypto_key.svg.png","//upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/50px-Question_book-new.svg.png","//bits.wikimedia.org/static-1.22wmf5/skins/vector/images/search-ltr.png?303-4","//bits.wikimedia.org/images/wikimedia-button.png","//bits.wikimedia.org/static-1.22wmf5/skins/common/images/poweredby_mediawiki_88x31.png"],"tags":[["nat","information"],["ban","information"],["alphabet","computer_science"],["base","exponentiation"],["e","mathematical_constant"],["nat","information"],["dit","information"],["entropy","statistical_thermodynamics#gibbs_entropy_formula"],["trace","linear_algebra"],["science","journal"],["science","journal"],["uniform_distribution","discrete"],["characterization","mathematics"],["redundancy","information_theory"],["entropy","arrow_of_time"]],"members":["e","base","entropy","nat","uniform_distribution","ban","characterization","alphabet","trace","science","redundancy","dit"],"related":["Information_theory","Random_variable","Expected_value","Self-information","Bit","Nat_(information)","Ban_(information)","Information_content","Claude_E._Shannon","A_Mathematical_Theory_of_Communication","Lossless","Data_compression","Independent_and_identically_distributed_random_variables","Shannon's_source_coding_theorem","Alphabet_(computer_science)","Fair_coin","Bernoulli_process","Binary_entropy_function","Entropy_rate","Bit","Bit","ASCII","Data_compression","Shannon's_source_coding_theorem","FLAC","H-theorem","Discrete_random_variable","Probability_mass_function","Expected_value","Self-information","Base_(exponentiation)","Logarithm","E_(mathematical_constant)","Bit","Nat_(information)","Dit_(information)","Limit_of_a_function","Bernoulli_process","Bit","Metric_entropy","Probability_mass_function","Die","Die","Die","Self-information","Thermodynamics","Statistical_thermodynamics","Entropy","Thermodynamic_system","Boltzmann_constant","J._Willard_Gibbs","Ludwig_Boltzmann","Quantum_physics","Von_Neumann_entropy","John_von_Neumann","Density_matrix","Trace_(linear_algebra)","Second_law_of_thermodynamics","Boltzmann's_constant","Edwin_Thompson_Jaynes","Statistical_mechanics","Boltzmann_constant","Maxwell's_demon","Rolf_Landauer","Landauer's_principle","Bit","PPM_compression_algorithm","Shannon-Hartley_theorem","Markov_chain","Typical_set","Huffman_coding","LZW","Arithmetic_coding","Kolmogorov_complexity","Checksum","Science_(journal)","Science_(journal)","Exabytes","Exabytes","Broadcast","Exabytes","Zettabytes","Telecommunication","Petabytes","Exabytes","Stochastic_process","Stationary_process","Quantities_of_information","Entropy_rate","Statistical_independence","ISBN","Kolmogorov_complexity","Computer_program","Universal_computer","Cryptanalysis","One-time_pad","Markov_model","Markov_source","Source_alphabet","Discrete_probability_distribution","Necessary_and_sufficient","Uniform_distribution_(discrete)","Characterization_(mathematics)","Continuous_function","Positive_integers","Redundancy_(information_theory)","Jensen_inequality","Probability_density_function","Differential_entropy","H-theorem","Boltzmann","Limiting_density_of_discrete_points","Bin_size","Kullback-Leibler_divergence","Measure","Absolutely_continuous","Counting_measure","Lebesgue_measure","Combinatorics","Loomis-Whitney_inequality","Orthogonal_projection","Shearer's_inequality","Conditional_entropy","Cross_entropy","Entropy_(arrow_of_time)","Entropy_encoding","Entropy_estimation","Entropy_power_inequality","Entropy_rate","Fisher_information","Hamming_distance","History_of_entropy","History_of_information_theory","Joint_entropy","Kolmogorov-Sinai_entropy","Dynamical_system","Levenshtein_distance","Mutual_information","Negentropy","Perplexity","Qualitative_variation","Statistical_dispersion","Nominal_distributions","Quantum_relative_entropy","Rényi_entropy","Shannon_index","Theil_index","Weighted_entropy","Principia_Cybernetica_Web"]}