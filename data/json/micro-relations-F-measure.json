{"cursor":"4065","size":15,"audio":[],"currentlang":"en","article":"In statistics, the 'F 1 score' (also 'F-score' or 'F-measure') is a\nmeasure of a test's accuracy. It considers both the precision p and the recall r\nof the test to compute the score: p is the number of correct results divided by\nthe number of all returned results and r is the number of correct results\ndivided by the number of results that should have been returned. The\nF 1 score can be interpreted as a weighted average of the precision\nand recall, where an F 1 score reaches its best value at 1 and worst\nscore at 0.\n\nThe traditional F-measure or balanced F-score ('F 1 score') is the\nharmonic mean of precision and recall:\n\n: F_1 = 2 \\cdot \\frac{\\mathrm{precision} \\cdot\n:\\mathrm{recall}}{\\mathrm{precision} + \\mathrm{recall}} .\n\nThe general formula for positive real Î² is:\n: F_\\beta = (1 + \\beta^2) \\cdot \\frac{\\mathrm{precision} \\cdot\n:\\mathrm{recall}}{(\\beta^2 \\cdot \\mathrm{precision}) + \\mathrm{recall}} .\n\nThe formula in terms of Type I and type II errors:\n\n: F_\\beta = \\frac {(1 + \\beta^2) \\cdot \\mathrm{true\\ positive} }{((1 +\n:\\beta^2) \\cdot \\mathrm{true\\ positive} + \\beta^2 \\cdot \\mathrm{false\\ negative}\n:+ \\mathrm{false\\ positive})}\\, .\n\nTwo other commonly used F measures are the F_{2} measure, which\nweights recall higher than precision, and the F_{0.5} measure,\nwhich puts more emphasis on precision than recall.\n\nThe F-measure was derived so that F_\\beta \"measures the\neffectiveness of retrieval with respect to a user who attaches Î² times as much\nimportance to recall as precision\". It is based on van Rijsbergen's\neffectiveness measure\n\n: E = 1 - \\left(\\frac{\\alpha}{P} + \\frac{1-\\alpha}{R}\\right)^{-1} .\n\nTheir relationship is F_\\beta = 1 - E where \\alpha=\\frac{1}{1\n+ \\beta^2} .\n","linknr":129,"url":"F-measure","recorded":1362480353,"links":13,"instances":["information_retrieval","metric","information_retrieval","metric"],"pdf":[],"categories":["Statistical natural language processing","Evaluation of machine translation","Statistical ratios","Summary statistics for contingency tables","Clustering criteria"],"headings":["Applications","See also","References"],"image":["//upload.wikimedia.org/math/9/9/1/991d55cc29b4867c88c6c22d438265f9.png","//upload.wikimedia.org/math/2/7/5/275f55f1ad01fc85820bf09fd9ab2831.png","//upload.wikimedia.org/math/2/a/a/2aacb6537c9b21c28c969f350026df20.png","//upload.wikimedia.org/math/c/e/f/cefd728131f7e2e03ded75b15c074cfd.png","//upload.wikimedia.org/math/b/c/4/bc43203d3f2a6fd0d1e44c0271a60b75.png","//upload.wikimedia.org/math/2/6/0/2602f5d6a565542e1a4c6562e8d97781.png","//upload.wikimedia.org/math/5/c/d/5cdb5e27c5238317d9cc43d26966aade.png","//upload.wikimedia.org/math/7/1/a/71a36af61708e4d2e4346d7f0a1976b1.png","//upload.wikimedia.org/math/a/b/8/ab8b37b97383b03561ff058aaebe3efd.png","//upload.wikimedia.org/math/2/6/0/2602f5d6a565542e1a4c6562e8d97781.png","//upload.wikimedia.org/wikipedia/commons/thumb/d/df/Bellcurve.svg/30px-Bellcurve.svg.png","//bits.wikimedia.org/static-1.21wmf10/skins/vector/images/search-ltr.png?303-4","//bits.wikimedia.org/images/wikimedia-button.png","//bits.wikimedia.org/static-1.21wmf10/skins/common/images/poweredby_mediawiki_88x31.png"],"tags":[["precision","information_retrieval"],["recall","information_retrieval"],["nist","metric"],["rouge","metric"]],"members":["recall","rouge","precision","nist"],"related":["Statistics","Precision_(information_retrieval)","Recall_(information_retrieval)","Type_I_and_type_II_errors","C._J._van_Rijsbergen","Information_retrieval","Web_search","Document_classification","Query_classification","Matthews_correlation_coefficient","Precision_and_recall","BLEU","NIST_(metric)","METEOR","ROUGE_(metric)","Word_error_rate","Noun_phrase_chunking","Receiver_operating_characteristic","Matthews_correlation_coefficient"]}