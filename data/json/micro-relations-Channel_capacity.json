{"cursor":"8153","size":15,"audio":[],"currentlang":"en","article":"In electrical engineering, computer science and information theory, 'channel\ncapacity' is the tightest upper bound on the amount of information that can be\nreliably transmitted over a communications channel. By the noisy-channel coding\ntheorem, the channel capacity of a given channel is the limiting information\nrate (in units of information per unit time) that can be achieved with\narbitrarily small error probability. \n\nInformation theory, developed by Claude E. Shannon during World War II, defines\nthe notion of channel capacity and provides a mathematical model by which one\ncan compute it. The key result states that the capacity of the channel, as\ndefined above, is given by the maximum of the mutual information between the\ninput and output of the channel, where the maximization is with respect to the\ninput distribution.\n","linknr":308,"url":"Channel_capacity","recorded":1362665111,"links":31,"instances":["information_theory","signal_processing","information","information_theory","communications"],"pdf":[],"categories":["Information theory","Telecommunication theory","Television terminology"],"headings":["Formal definition","Noisy-channel coding theorem","Example application","Channel capacity in wireless communications","See also","References"],"image":["//upload.wikimedia.org/wikipedia/commons/thumb/4/48/Comm_Channel.svg/500px-Comm_Channel.svg.png","//upload.wikimedia.org/math/c/d/f/cdf3e29a0297579b1d498761c75c267d.png","//upload.wikimedia.org/math/f/6/e/f6e26e4187b5752a5eaa2851b30d8233.png","//upload.wikimedia.org/math/7/a/d/7ade9b9dd96b0f853427fea2c57f4d15.png","//upload.wikimedia.org/math/5/f/1/5f1e869d6063d479651105a8c1242b49.png","//upload.wikimedia.org/math/d/6/3/d63d4e59d4cd0edf034d356f9bdb8fd8.png","//upload.wikimedia.org/math/7/2/2/72268ae9e9e089bc0ae3c61b7435f434.png","//upload.wikimedia.org/math/c/a/9/ca9ff13b11e6a041d69c999c19a74366.png","//upload.wikimedia.org/math/7/8/8/7883486c06d60346898e3356af99e9f6.png","//upload.wikimedia.org/math/5/4/1/541c5b0c63de441761aaa533fc580da6.png","//upload.wikimedia.org/math/4/3/0/430640ab9632d9ef7eef75311fb5f2f5.png","//upload.wikimedia.org/math/8/3/5/8357f2d642ae4e6902976c9f7c45b171.png","//upload.wikimedia.org/math/c/f/e/cfe0f688fce7f13988607326dacfe5e5.png","//upload.wikimedia.org/math/d/6/d/d6dcc2c4f5c0daade5d6e25e28101ec0.png","//upload.wikimedia.org/math/f/8/6/f8623eeb1df67130b1b4f2b277cb2dde.png","//upload.wikimedia.org/math/e/6/8/e680bced37791a847689d33d1e136725.png","//upload.wikimedia.org/wikipedia/commons/thumb/9/94/Channel_Capacity_with_Power-_and_Bandwidth-Limited_Regimes.png/220px-Channel_Capacity_with_Power-_and_Bandwidth-Limited_Regimes.png","//bits.wikimedia.org/static-1.21wmf9/skins/common/images/magnify-clip.png","//upload.wikimedia.org/math/f/4/8/f48a537cd25fd9c0b29be8c8bd4072f6.png","//upload.wikimedia.org/math/f/a/8/fa863184a62e5bfeb21f1960bc1ce4d1.png","//upload.wikimedia.org/math/1/7/2/172e099114320f609082558f712831f6.png","//upload.wikimedia.org/math/8/e/8/8e8c4ac9ddcba78ed490e57c7e9c278b.png","//upload.wikimedia.org/math/7/b/8/7b8b965ad4bca0e41ab51de7b31363a1.png","//upload.wikimedia.org/math/e/0/5/e05a30d96800384dd38b22851322a6b5.png","//upload.wikimedia.org/math/6/d/f/6df24a0917d06d8c4522e86221f70387.png","//upload.wikimedia.org/math/9/c/f/9cf11232ede4c556606964e6597a7c52.png","//upload.wikimedia.org/math/e/1/e/e1e1d3d40573127e9ee0480caf1283d6.png","//upload.wikimedia.org/math/e/d/a/eda6103a3de4e995a48002a1b29bda17.png","//upload.wikimedia.org/math/e/1/e/e1e1d3d40573127e9ee0480caf1283d6.png","//upload.wikimedia.org/math/6/0/a/60afd4b9992783fbc67e043615ec1264.png","//upload.wikimedia.org/math/c/5/0/c50b9e82e318d4c163e4b1b060f7daf5.png","//upload.wikimedia.org/math/c/5/0/c50b9e82e318d4c163e4b1b060f7daf5.png","//upload.wikimedia.org/math/c/3/d/c3de0be30034db54441f794f9cbaf04d.png","//upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/50px-Question_book-new.svg.png","//bits.wikimedia.org/static-1.21wmf10/skins/vector/images/search-ltr.png?303-4","//bits.wikimedia.org/images/wikimedia-button.png","//bits.wikimedia.org/static-1.21wmf10/skins/common/images/poweredby_mediawiki_88x31.png"],"tags":[["channel","communications"],["channel","communications"],["bandwidth","signal_processing"],["nat","information"],["bandwidth","computing"],["bandwidth","signal_processing"],["redundancy","information_theory"],["receiver","information_theory"]],"members":["receiver","bandwidth","nat","redundancy","channel"],"related":["Electrical_engineering","Computer_science","Information_theory","Information","Channel_(communications)","Noisy-channel_coding_theorem","Channel_(communications)","Information_entropy","Information_theory","Claude_E._Shannon","World_War_II","Mutual_information","Conditional_distribution","Marginal_distribution","Mutual_information","Noisy-channel_coding_theorem","Additive_white_Gaussian_noise","Bandwidth_(signal_processing)","Signal-to-noise_ratio","Shannon–Hartley_theorem","Bits_per_second","Logarithm","Nat_(information)","Natural_logarithm","Hertz","Decibel","MIMO","Power_spectral_density","Fading","Waterfilling","Fading","Fading","Bandwidth_(computing)","Bandwidth_(signal_processing)","Bit_rate","Code_rate","Error_exponent","Nyquist_rate","Negentropy","Redundancy_(information_theory)","Sender","Encoder","Decoder","Receiver_(Information_Theory)","Shannon–Hartley_theorem","Spectral_efficiency","Throughput","MIMO","Cooperative_diversity"]}